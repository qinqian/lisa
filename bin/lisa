#!/usr/bin/env python
"""lisa fire interface
render Snakefile conditionally
"""
from functools import reduce
import yaml
import numpy as np
import pandas as pd
import math
import sys
import os
import argparse
import pickle
import glob
import h5py
import fire
from pkg_resources import resource_filename
from string import Template
import json
from lisa import Config

class LisaPipeline(object):
    """ LISA pipeline for processing multiple files """
    def __init__(self, prefix, species, epigenome, cluster, only_newhdf5=False, sample_number=10, web=False):
        """ species: the species of gene_sets,
            epigenome: a list of marks, e.g. ['H3K4me3', 'H3K27ac'],
                       for multiple_bigwig2hdf, this can be covariates, such as `GC`
            gene_sets: a list of path to gene list file, the file contains a gene per line.
        """
        self.prefix = prefix
        self.species = species
        self.epigenome = epigenome
        self.yml_data = dict(
            species=self.species,
            epigenome=self.epigenome,
            bigwigs=None,
            fastqs=None,
            model=False,
            gene_sets=None,
            sample_number=sample_number,
            cluster=cluster,
            only_newhdf5=only_newhdf5,
            web=web,
            prefix=self.prefix)

    def multiple_fastq2bigwig(self, *fastqs):
        """ input fastq and generate bigwig
        """
        self.yml_data['fastqs'] = fastqs
        self.yml_data['prefix'] = "%s" % self.prefix
        config = Config(resource_filename("lisa", "lisa.ini"), self.species)
        self.yml_data['index'] = config.get_index
        print(config.get_index)
        print(self.yml_data)

        with open('%s.yml' % self.prefix, 'w') as outfile:
            yaml.dump(self.yml_data, outfile, default_flow_style=False)
        # render workflow Snakefile
        snakemake_template = resource_filename("lisa.workflows", "Snakefile")
        with open(snakemake_template) as snake:
            template = Template(snake.read())
            with open('Snakefile.fastq', 'w') as outf:
                outf.write(template.substitute(
                    {'config': "%s.yml" % self.prefix}))
        os.system("snakemake -s Snakefile.fastq -j 8 --use-conda")

    def multiple_bigwig2hdf(self, *bigwigs):
        """ input multiple bigwig files, generate hdf5 file for RP
        and read count with snakemake """
        print('bigwigs:--------', bigwigs)
        self.yml_data['bigwigs'] = bigwigs
        self.yml_data['prefix'] = "%s" % self.prefix
        print(self.yml_data)

        with open('%s.yml' % self.prefix, 'w') as outfile:
            yaml.dump(self.yml_data, outfile, default_flow_style=False)
        # render workflow Snakefile
        snakemake_template = resource_filename("lisa.workflows", "Snakefile")
        with open(snakemake_template) as snake:
            template = Template(snake.read())
            with open('Snakefile.hdf5', 'w') as outf:
                outf.write(template.substitute(
                    {'config': "%s.yml" % self.prefix}))
        os.system("snakemake -s Snakefile.hdf5 -j 4 --use-conda")


    def model(self, method, threads, covariates, random, new_count_h5, new_rp_h5, *gene_sets):
        """ modeling a batch of gene sets with multiple epigenome types

        covariates: True or False, use GC covariates or no

        new_count_h5 and new_rp_h5 must from the same epigenome mark, the same samples, and
        matched by sample names
        """
        # generate snakemake config file
        self.yml_data['method'] = method
        self.yml_data['model'] = True
        self.yml_data['gene_sets'] = gene_sets
        self.yml_data['random'] = random
        self.yml_data['covariates'] = covariates

        self.yml_data['new_count_h5'] = new_count_h5
        self.yml_data['new_rp_h5'] = new_rp_h5

        with open('%s.yml' % self.prefix, 'w') as outfile:
            yaml.dump(self.yml_data, outfile,
                      default_flow_style=False)

        # render workflow Snakefile
        snakemake_template = resource_filename("lisa.workflows", "Snakefile")
        with open(snakemake_template) as snake:
            template = Template(snake.read())
            with open('%s.Snakefile.model' % self.prefix, 'w') as outf:
                outf.write(template.substitute(
                    {'config': "%s.yml" % self.prefix}))
        os.system("snakemake --profile %s.profile -j %s --latency-wait 8 -s %s.Snakefile.model --use-conda"
                  % (self.prefix, threads, self.prefix))

if __name__ == '__main__':
    fire.Fire(LisaPipeline)
