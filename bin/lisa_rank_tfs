#!/usr/bin/env python

""" Lisa interface to rank TFs based on the differential
expression model and whole genome 1kb read count of the samples
"""

from sklearn.cluster import MiniBatchKMeans
from lisa.rank import get_insilico_knockout_tensor_op, rank_by_entropy
from lisa.data import EpigenomeData
from lisa.utils import Weight, one_side_ks_test, convert_name, mannwhitneyu_test, multiple_apply
import h5py

import pandas as pd
import numpy as np
from functools import wraps
import fire
import time
from multiprocessing import Pool, cpu_count

def test(args):
    x, y = args
    return mannwhitneyu_test(x,y,how="greater")

class LisaRank(object):
    """rank the TFs given the gene sets
        1. In silico knockout epigenome signal on motif or TF ChIP-seq peak
        2. cluster the selected sample epigenome signal, then compute relative entropy
    """
    def __init__(self, species, prefix, background, foreground, only_newhdf5=False):
        self.epigenome = EpigenomeData(species, None)
        self.species = species
        self.background_genes = np.genfromtxt(background, dtype='str')
        self.foreground_genes = np.genfromtxt(foreground, dtype='str')

        self.diff_gene_num = len(self.foreground_genes)
        self.all_genes = np.concatenate([self.foreground_genes, self.background_genes])
        self.prefix = prefix
        self.only_newhdf5 = only_newhdf5

    def get_hdf(self, dtype):
        """ get corresponding TF binding data type for 100bp window hit
        """
        tfbs_dict = dict(
            motif99=self.epigenome.config.get_motif_index(99),
            #motif98=self.epigenome.config.get_motif_index(98),
            #motif97=self.epigenome.config.get_motif_index(97),
            chipseq=self.epigenome.config.tf_chipseq
        )
        return tfbs_dict[dtype]

    def direct(self):
        """ rank TF based on TF ChIP-seq peak regulatory potential difference
        between foreground genes and background genes
        """
        # gene x tf sample
        beta_df = self.epigenome.get_beta(self.all_genes)
        # pvalue = beta_df.apply(lambda x: one_side_ks_test(x[:self.diff_gene_num],
        #                                                   x[self.diff_gene_num:]),
        #                        axis=0)

        #pvalue = beta_df.apply(lambda x: mannwhitneyu_test(x[:self.diff_gene_num],
        #                                                   x[self.diff_gene_num:],
        #                                                   how="greater"),
        #                       axis=0)

        pvalue = multiple_apply(test, beta_df, 
                                np.arange(self.diff_gene_num), np.arange(self.diff_gene_num, beta_df.shape[0]), 4)
        pvalue.index = self._get_tfbs_annotation(pvalue.index, 'chipseq')

        beta_df.columns = pvalue.index
        beta_df.loc['pvalue', :] = pvalue.iloc[:, 0]
        beta_df = beta_df.iloc[:, np.argsort(pvalue.iloc[:, 0].values)]

        pvalue = pvalue.iloc[:, 0:1]
        pvalue.columns = ['pval']
        pvalue = pvalue.sort_values(['pval'], ascending=True, inplace=False)
        print(pvalue.head())
        match_meta = self._get_tfbs_annotation(pvalue.index, 'chipseq', is_full=True)
        match_meta.index = pvalue.index
        pvalue = pd.concat([pvalue, match_meta], axis=1)

        beta_df.to_csv('%s.lisa_peak_rp.csv' % self.prefix)
        beta_df.iloc[np.arange(self.diff_gene_num), :300].to_csv('%s.lisa_target_peak_rp.csv' % self.prefix)
        pvalue.to_csv('%s.lisa_direct.csv' % self.prefix)

    def _prepare_data(self, bin_length):
        # load gene TSS bins
        gene_tss_bin = self.epigenome.get_gene_tss_bin
        gene_bins, gene_bin_centers, gene_chrs, gene_tss = [], [], [], []
        for gene in self.all_genes:
            # center cooridinates, 0-based bin index
            gene_bins.append(int(gene_tss_bin[gene][1]))
            gene_bin_centers.append(int(gene_tss_bin[gene][0]))
            gene_chrs.append(gene.split(":")[0])
            gene_tss.append(int(gene.split(":")[1]))
        gene_bins = np.array(gene_bins)
        gene_bin_centers = np.array(gene_bin_centers)
        gene_tss = np.array(gene_tss)
        bin_center_2d, bin_2d = [], []
        # get the bin center matrix
        for i in range(-100, 100):
            # bin center base coordinate
            bin_center_2d.append(gene_bin_centers + i * bin_length)
            # TSS bin index
            bin_2d.append(gene_bins + i)
        # setup bins for delta rp
        # genes x 200bin
        bin_center_2d = np.vstack(bin_center_2d).T
        bin_2d = np.vstack(bin_2d).T
        dist = (bin_center_2d.T - gene_tss).T

        # compute boundary masked bins
        chrom_bin_mask = self.epigenome.get_chr_boundary_mask(gene_chrs)
        bin_2d_left = bin_2d >= 0 # left chromosome margin
        bin_2d_right = (bin_2d.T - chrom_bin_mask).T <= 0 # right chromosome margin

        boundary_mask = bin_2d_left & bin_2d_right
        bin_2d = bin_2d * boundary_mask

        # compute the weight, each bin center distance from TSS
        weight_obj = Weight(bin_length)  # 1kb windows
        # gene x 200bin
        weight_obj.balance_weight(dist)
        weight = weight_obj.get_weight() * boundary_mask
        return bin_2d, weight

    def knockout(self, epigenome, coefficient, covariates, dtype, new_h5_rp, new_h5_count):
        """ rank TFs by In silico knockout of the epigenome signals

        there are two modes to rank
        species: hg38 or mm10
        prefix: output prefix of Lisa
        epigenome: epigenome type, e.g. H3K27ac
        covariates: True or False, to use GC covariates or not
        coefficient: coefficients csv file

        dtype: choose from 'motif97', 'motif98', 'motif99' or 'chipseq'
               different TF binding data to knock out
        """
        start = time.time()

        self.epigenome.epigenome = epigenome
        # load raw regulatory potential
        raw_reg = self.epigenome.get_RP
        # raw_reg.index = raw_reg.index.map(lambda x:x.upper())  # fix the symbol to uppercase, not necessary, comment

        if new_h5_rp != None: # add hdf5 from fastqs or bigwigs for raw rp
            with h5py.File(new_h5_rp, mode='r', swmr=True) as st:
                eids = list(map(lambda x: x.decode('utf-8'), st["IDs"][...]))
                df = pd.DataFrame(st["RP"][...], index=raw_reg.index,
                                  columns=eids)

                if not self.only_newhdf5:
                    raw_reg = pd.concat([raw_reg, df], axis=1)
                else:
                    raw_reg = df

        if covariates:
            raw_reg = pd.concat([raw_reg, self.epigenome.get_covariates_reg], axis=1)

        # load model coefficients with sample ids in one csv file
        coef = pd.read_csv(coefficient, encoding="ISO-8859-1", index_col=0)
        coef.index = coef.index.astype(str)

        # select foreground and background selected genes
        # and reorder the sample names as the coefficient order
        raw_reg = raw_reg.loc[self.all_genes, list(coef.index)]
        print(raw_reg.shape)

        # lisa prediction
        normalized_reg = np.log2(raw_reg.values+1)
        original_median = np.mean(normalized_reg, axis=0)
        normalized_reg = normalized_reg - original_median
        lisa_prediction = np.dot(normalized_reg, coef.iloc[:, 0].values)
        print(time.time()-start)

        # load chromatin boundary mask array
        bin_length = 1000
        print(bin_length)
        # get refseq information array
        # bin_2d (genes x 200bin, already masked the bins out of chrom end)
        # weight (genes x 200bin, already masked the bins out of chrom end)
        bin_2d, weight = \
            self._prepare_data(bin_length)
        print(bin_2d.shape)
        print(weight.shape)
        print(time.time()-start)

        print('loading read count')
        # add sorted selected_bins list for faster IO loading
        selected_bins = np.unique(bin_2d.reshape(-1))  ## only preserve the bins around gene tss with > 0 read count
        # load 1kb average read count
        read_count = self.epigenome.get_count(list(coef.index), covariates, new_h5_count, only_newh5=self.only_newhdf5, selected_bins=selected_bins[1:])  ## TODO: check only_newh5 option
        print(time.time()-start)
        print('read count loaded')

        # extract signals in bins for all samples
        # gene x bin x sample
        signal = read_count[bin_2d]
        # sample x gene x bin
        signal = signal.transpose(2, 0, 1)
        signal = signal * bin_length # average signal x window size
        # precompute sample x gene x bin
        precompute = signal * weight
        # sample x (gene1_bin1, gene1_bin2...gene2_bin1, gene2_bin2...)
        precompute = \
            precompute.reshape((precompute.shape[0], -1))

        theano_deltarp_function = get_insilico_knockout_tensor_op(lisa_prediction, precompute, coef, original_median)
        # load 100bp to 1kb mapping files
        bin_100_to_1kb = np.load(self.epigenome.config.genome_window_map) # 0-based

        # get TF binding sites in 100bp windows,
        # motif index is 0-based in 100bp windows
        # TF ChIP-seq peak index is 1-based in 100bp windows
        offset = -1 if dtype == 'chipseq' else 0
        delta_rps = []
        sids = []

        # IO do not use function calls
        with h5py.File(self.get_hdf(dtype), mode='r', swmr=True) as store:  ## add swmr > 2.5.0, h5py.version.hdf5_version_tuple > 1.10
        #with h5py.File(self.get_hdf(dtype), mode='r') as store:  ## add swmr > 2.5.0, h5py.version.hdf5_version_tuple > 1.10
            IDs = store['IDs'][...]
            for sid in IDs:
                sids.append(convert_name(sid))

            def get_ISDRP(sid):
                tfbs_index = store[sid][...]  # 100 bp window index vector
                tfbs_binary = np.zeros(bin_100_to_1kb[-1] + 1, dtype=np.uint8)
                tfbs_binary[bin_100_to_1kb[tfbs_index+offset]] = 1
                # gene x bin
                E = tfbs_binary[bin_2d]
                E = E.reshape(1, -1) # 1 x (gene, bin)
                E = np.logical_not(E)
                return theano_deltarp_function(E)

            ## using 4 threads
            # any original python Pool neds the function to be pickled
            # not work for nested functions
            # with Pool(4) as pool: 
            #     delta_rps = pool.map(get_ISDRP, IDs) 

            # try pathos dill to serialize python function
            # with Pool2(4) as pool: 
            #     delta_rps = pool.map(get_ISDRP, IDs) 

            for sid in IDs:
                 delta_rps.append(get_ISDRP(sid))
            #    tfbs_index = store[sid][...]
            #    tfbs_binary = np.zeros(bin_100_to_1kb[-1] + 1, dtype=np.int32)
            #    # map 100bp windows back to 1kb windows
            #    # TODO: add DNase-seq peak filter
            #    tfbs_binary[bin_100_to_1kb[tfbs_index+offset]] = 1
            #    # gene x bin
            #    E = tfbs_binary[bin_2d]
            #    E = E.reshape(1, -1) # 1 x (gene, bin)
            #    E = np.logical_not(E)
            #    delta_rps.append(theano_deltarp_function(E))
            #    sids.append(convert_name(sid))

        delta_rps = np.vstack(delta_rps).T # gene x tfbs (motif or peak)
        delta_rp_df = pd.DataFrame(delta_rps, columns=sids, index=self.all_genes)
        print('statistics done')
        print(time.time()-start)
        delta_rp_df.columns = self._get_tfbs_annotation(delta_rp_df.columns, dtype)
        # pvalue = delta_rp_df.apply(lambda x: one_side_ks_test(x[:self.diff_gene_num],
        #                                                       x[self.diff_gene_num:]),
        #                            axis=0)
        #pvalue = delta_rp_df.apply(lambda x: mannwhitneyu_test(x[:self.diff_gene_num],
        #                                                       x[self.diff_gene_num:],
        #                                                       how="greater"),
        #                           axis=0)
        # 4 processes to apply statistical test across ISD-RP
        pvalue = multiple_apply(test, delta_rp_df, 
                                np.arange(self.diff_gene_num), np.arange(self.diff_gene_num, delta_rp_df.shape[0]), 4)
        pvalue = pvalue.iloc[:, 0]

        delta_rp_df.loc['pvalue', :] = pvalue
        delta_rp_df = delta_rp_df.iloc[:, np.argsort(pvalue)]

        diff_binary = np.zeros(len(self.all_genes)+1) # add 1 to align the p-value
        diff_binary[: self.diff_gene_num] = 1

        delta_rp_df.loc[:, 'diff_status'] = diff_binary
        delta_rp_df.to_csv("%s.%s.%s.csv" % (self.prefix, self.epigenome.epigenome, dtype))

        # output target delta rp
        delta_rp_df.iloc[np.arange(self.diff_gene_num), :300].to_csv("%s.%s.%s.target.csv" % (self.prefix, self.epigenome.epigenome, dtype))

        pvalue = pd.DataFrame(pvalue)
        pvalue.columns = ['pval']
        pvalue = pvalue.sort_values(['pval'], ascending=True, inplace=False)
        print(pvalue.head())
        match_meta = self._get_tfbs_annotation(pvalue.index, dtype, is_full=True)
        match_meta.index = pvalue.index
        pvalue = pd.concat([pvalue, match_meta], axis=1)
        print(pvalue.head())
        pvalue.to_csv("%s.%s.%s.p_value.csv" % (self.prefix, self.epigenome.epigenome, dtype))

    def _get_tfbs_annotation(self, cols, dtype, is_qc=False, is_full=False):
        # annotation of chipseq dc ids or motif ids
        cols_new = []
        cols = list(map(lambda x:x.split('|')[0], cols))
        for i in cols:
            try:
                cols_new.append(i.decode('utf-8').split('_')[0])
            except:
                cols_new.append(i.split('_')[0])
        if dtype == 'chipseq':
            try:
                selection_ids = list(map(int, cols_new))
            except ValueError: ## imputation data without cistrome id to search
                return cols
            meta = pd.read_table(self.epigenome.config.get_meta,
                                 encoding="ISO-8859-1",
                                 index_col=0)
            if is_qc:
                meta = meta.loc[meta.loc[:, 'qc']==1, :]
            selection = 'factor'
        else:
            selection_ids = cols_new
            selection = 'symbol'
            meta = pd.read_table(self.epigenome.config.get_motif_meta, encoding="ISO-8859-1", index_col=0)
        if not is_full:
            annotation = meta.loc[selection_ids, selection]
            result = list(map(lambda x: '|'.join(map(str, x)), 
                              zip(annotation.index, 
                                  annotation)))
        else:
            print(selection_ids[:5])
            result = meta.loc[selection_ids, :]
            print(result.head())
        return result

    def entropy(self, epigenome, coefficient, covariates, dtype, new_h5):
        """ first cluster selected samples by regions
        then evaluate kl divergence
        """
        self.epigenome.epigenome = epigenome

        # load model coefficients with sample ids in one csv file
        coef = pd.read_csv(coefficient, encoding="ISO-8859-1", index_col=0)
        coef.index = coef.index.astype(str)

        # load chromatin boundary mask array
        bin_length = 1000
        # get refseq information array
        # bin_2d (genes x 200bin, already masked the bins out of chrom end)
        # weight (genes x 200bin, already masked the bins out of chrom end)
        bin_2d, _ = \
            self._prepare_data(bin_length)

        bin_1d = bin_2d.reshape(-1)
        bin_1d = np.unique(bin_1d, return_index=False)        # remove duplicates of bins
        bin_1d = bin_1d[1:]                                   # the first element is the masked bin

        # load 1kb average read count

        read_count = self.epigenome.get_count(list(coef.index), covariates, new_h5, only_newh5=self.only_newhdf5, selected_bins=bin_1d)
        #### read_count = read_count[bin_1d]

        norm = np.log2(read_count+1)
        norm = norm - np.mean(norm)
        norm = norm * np.abs(coef.iloc[:, 0].values)

        n_clusters = 10  # 2,5,10 cluster?
        kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=0).fit(norm)
        labels_order = np.argsort(kmeans.labels_)
        norm = norm[labels_order]
        labels = kmeans.labels_[labels_order]
        cluster_stat = np.unique(labels, return_counts=True)

        prop_dict = {}
        cluster_dict = {}
        for cluster, ct in zip(*cluster_stat):
            cluster_dict[cluster] = ct

        # load 100bp to 1kb mapping files
        bin_100_to_1kb = np.load(self.epigenome.config.genome_window_map) # 0-based
        offset = -1 if dtype == 'chipseq' else 0
        with h5py.File(self.get_hdf(dtype), mode='r') as store:
            ids = store['IDs']
            for tfbs_id in ids:
                # TODO: add DNase-seq peak filter
                tfbs_index = store[tfbs_id][...] + offset
                # 1kb window
                tfbs_bin = np.zeros(bin_100_to_1kb[-1] + 1, dtype=np.int32)
                # 1kb 0-1 vector
                tfbs_bin[bin_100_to_1kb[tfbs_index]] = 1
                is_s = np.asarray(tfbs_bin, dtype=np.bool)
                is_s = is_s[bin_1d]           # the window near the genes
                is_s = is_s[labels_order]     # order by cluster label
                labels_tfbs = labels[is_s]    # get the labels
                stat = {}
                # cluster label distribution for the tfbs data
                for i, j in zip(*np.unique(labels_tfbs, return_counts=True)):
                    stat[i] = j
                prop_dict[tfbs_id] = []
                for key in cluster_dict:
                    prop_dict[tfbs_id].append(stat.get(key,0))

        prop_dict['cluster_number'] = []
        for key in cluster_dict:
            prop_dict['cluster_number'].append(cluster_dict[key])
        prop =  pd.DataFrame(prop_dict, index=['cluster%s' %s for s in cluster_dict])
        prop.to_csv('%s.%s.%s.cluster_stat.csv' % (self.prefix, self.epigenome.epigenome, dtype))

        divergence = rank_by_entropy(prop)
        divergence.index = self._get_tfbs_annotation(divergence.index, dtype)
        divergence.to_csv('%s.%s.%s.entropy_rank.csv' % (self.prefix, self.epigenome.epigenome, dtype))

if __name__ == '__main__':
    fire.Fire(LisaRank)
